---
title: "lab1"
author: "ShamanGarcia"
date: "2025-11-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown
# Class example

Below is the in class example that shows the way in which you can use world data (accessed through tmap). The map generated shows the countries of the world and symbology for each country based on the GDP. 

```{r}
#Class example map
#plot2
## here we are using a simple dataset of the world 
# tmap_mode("plot")
library(ggplot2)
library(sf)
library(tidyverse)
library(tmap)
data("World")
tm_shape(World) +
  tm_polygons("gdp_cap_est", style='quantile', legend.title = "GDP Per Capita Estimate")

## the view mode creates an interactive map
tmap_mode("view")
```

## Personal Map
# Number of bordering countries

My idea for the personal map part of the assignment goes back to the daily geography games I like to play. One game in specific, GeoGrid, asks you to name a country that lies in the intersection of two catergories (flag with two colors, high GDP, touches the Atlantic ocean...etc). One category, "Borders X amount of countries", I always find quite difficult. I thought making a map that shows the countries of the world with symbology based on the number of bordering countries would help me with my daily GeoGrid-ing!

In order to create the map, I had to find information for the number of bordering countries. I found a Wikipedia page that contained this information and turned it into a google sheet. 
I cleaned up that data to make sure the country names matched those that appeared in the "World" data that came from tmap. I then used a attribute join to combine these two datasets based on the "name" column that contained the country names.

Finally, I used some attributes of the tm_shape function in order to get a map that had an accurate legend and easy to read information about the number and names of the bordering countries.

```{r}
# Personal Map
library(dplyr)
library(tmap)
library(sf)

data("World")

# Read borders CSV
borders <- st_read("borderfull.csv")

# Join world data with borders
world_joined <- left_join(World, borders, by = "name") %>%
  select(name, Number.of.Bordering.Countries, Bordering.countries) %>%
  mutate(
    # Set factor order for the legend
    Number.of.Bordering.Countries = factor(
      Number.of.Bordering.Countries,
      levels = c(1,2,3,4,5,6,7,8,9,10,11,14,NA),
      exclude = NULL
    ),
    # Add HTML line breaks for better popup readability
    Bordering.countries = gsub(" (?=[A-Z][a-z]+:)", "<br>", Bordering.countries, perl = TRUE)
  )

# Switch to interactive mode
tmap_mode("view")

# Create the map
tm_shape(world_joined) +
  tm_polygons(
    "Number.of.Bordering.Countries",
    style = "cat",
    palette = "Set1",
    title = "Number of Bordering Countries",
    colorNA = "grey90",
    textNA = "Missing",
    id = "name",
    popup.vars = c(
      "Number of Borders" = "Number.of.Bordering.Countries",
      "Bordering Countries" = "Bordering.countries"
    ),
    popup.format = list(html.escape = FALSE)
  ) +
  tm_layout(
    legend.position = c("right", "bottom"),
    legend.text.size = 0.6,    # shrink text
    legend.title.size = 0.8,   # shrink title
    legend.bg.alpha = 0.7      # slightly transparent background
  )

```

### Lab Questions:

#### Discuss the advantages and challenges associated with an open data science approach. Provide an example based on this week’s reading. (1-2 paragraphs)

An open data science approach means sharing data, code, and results so others can use and build on them. This helps make research more transparent, reproducible, and collaborative. It also speeds up discoveries because people don’t have to start from scratch. However, it can be challenging to protect privacy, keep data accurate, and give everyone equal access to tools and information. For example, this week’s reading showed how open climate data lets scientists worldwide study weather patterns together, but it also creates issues with data quality and consistency.

#### Create a markdown document that showcases an analysis of this week’s data or any other dataset of your choice. Include descriptive text that explains your analysis, and incorporate figures and geovisualizations.Include 1 chart and 1 map. Structure and explain your analysis with text, headings, highlights, images and other markdown basics.

Completed above.

#### Bonus: Capture a screenshot of the history of your Git commits. Share your strategy for utilizing Git in your workflow.

![Commit history](siteimages/commits.png)
In terms of version control, I mostly committed changes anytime I got to a point where the website or webpage I was working on looked how I envisioned it or when I added some functionality. 

